version: '3.8'

# GraphRAG Docker Services
# Neo4j data persists in bind-mounted directory
# NIM/vLLM caches use named volumes for container compatibility

services:
  # Neo4j Graph Database (port 7474, 7687)
  neo4j:
    container_name: neo4j-graphrag
    image: neo4j:latest
    restart: unless-stopped
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-graphrag2024}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
    volumes:
      - ../neo4j/data:/data
      - ../neo4j/logs:/logs
      - ../neo4j/plugins:/plugins
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://localhost:7474 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Nemotron LLM NIM (port 12800, GPU 7)
  nemotron-llm:
    container_name: nemotron-graphrag
    image: nvcr.io/nim/nvidia/nvidia-nemotron-nano-9b-v2:latest
    restart: unless-stopped
    runtime: nvidia
    ports:
      - "12800:8000"
    environment:
      - NGC_API_KEY=${NGC_API_KEY}
      - NVIDIA_VISIBLE_DEVICES=7
      - CUDA_VISIBLE_DEVICES=0
      - NIM_MAX_NUM_SEQS=64
      - NIM_MAX_MODEL_LEN=8192
    volumes:
      - nim_llm_cache:/opt/nim/.cache
    shm_size: '16gb'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 180s

  # NeMo Embedding NIM (port 12801, GPU 4,5)
  nemo-embedding:
    container_name: docker-nemo-embedding-1
    image: nvcr.io/nim/nvidia/nv-embedqa-mistral-7b-v2:1.0.1
    restart: unless-stopped
    runtime: nvidia
    ports:
      - "12801:8000"
    environment:
      - NGC_API_KEY=${NGC_API_KEY}
      - NIM_TRITON_PERFORMANCE_MODE=latency
      - NVIDIA_VISIBLE_DEVICES=4,5
      - CUDA_VISIBLE_DEVICES=0,1
    volumes:
      - nim_embed_cache:/opt/nim/.cache
    shm_size: '16gb'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 180s

  # Mistral NeMo Code LLM (vLLM, port 12802, GPU 0)
  mistral-nemo-coder:
    container_name: docker-mistral-nemo-coder-1
    image: vllm/vllm-openai:latest
    restart: unless-stopped
    runtime: nvidia
    ports:
      - "12802:8000"
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
      - NVIDIA_VISIBLE_DEVICES=0
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - huggingface_cache:/root/.cache/huggingface
    command: >
      --model mistralai/Mistral-Nemo-Instruct-2407
      --max-model-len 8192
      --gpu-memory-utilization 0.9
    shm_size: '16gb'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 180s

# Named volumes for model caches (persist across container restarts)
volumes:
  nim_llm_cache:
    name: graphrag_nim_llm_cache
  nim_embed_cache:
    name: graphrag_nim_embed_cache
  huggingface_cache:
    name: graphrag_huggingface_cache
